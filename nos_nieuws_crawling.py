import streamlit as st
from datetime import datetime
from collections import Counter
import csv
import re
import io
import feedparser
import html2text

st.set_page_config(page_title="NOS RSS crawler", layout="wide")
st.title("NOS RSS crawler & trefwoorden")

# --------------------- Disclaimer ---------------------
st.info(
    """
    ì´ ì•±ì€ **NOSì˜ ê³µì‹ RSS í”¼ë“œ**ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ë³¸ë¬¸ ì „ë¬¸ì„ ì €ì¥/ë°°í¬í•˜ì§€ ì•Šìœ¼ë©°,
    í™”ë©´ì—ëŠ” **ì§§ì€ ìš”ì•½(ìµœëŒ€ 3ë¬¸ì¥Â·500ì)** ë§Œ í‘œì‹œí•©ë‹ˆë‹¤. ëª¨ë“  ì €ì‘ê¶Œì€ ì› ì¶œì²˜(NOS.nl)ì— ìˆìŠµë‹ˆë‹¤.
    """,
    icon="â„¹ï¸",
)

# --------------------- Stopwoorden ---------------------
dutch_stopwords = {
    "de", "en", "van", "ik", "te", "dat", "die", "in", "een", "hij", "het", "niet",
    "zijn", "is", "was", "op", "aan", "met", "als", "voor", "had", "er", "maar",
    "om", "hem", "dan", "zou", "of", "wat", "mijn", "men", "dit", "zo", "door",
    "over", "ze", "zich", "bij", "ook", "tot", "je", "mij", "uit", "der", "daar",
    "haar", "naar", "heb", "hoe", "heeft", "hebben", "deze", "u", "want", "nog",
    "zal", "me", "zij", "nu", "ge", "geen", "omdat", "iets", "worden", "toch",
    "al", "waren", "veel", "meer", "doen", "toen", "ëª¨et", "ben", "zonder", "kan",
    "hun", "dus", "alles", "onder", "ja", "werd", "wezen", "zelf", "tegen",
    "komen", "goed", "hier", "wie", "waarom"
}

# --------------------- Helper: safe preview ---------------------
def make_safe_preview(md_text: str, max_sentences: int = 3, max_chars: int = 500) -> str:
    """RSS ìš”ì•½ ë°˜í™˜
    - ë¬¸ì¥ ê¸°ì¤€ ìµœëŒ€ 3ë¬¸ì¥
    - ì´ ê¸¸ì´ ìµœëŒ€ 500ì
    """
    if not md_text:
        return ""
    # ê³µë°± ì •ë¦¬
    text = re.sub(r"\s+", " ", md_text).strip()
    # ë‹¨ìˆœ ë¬¸ì¥ ë¶„ë¦¬ (., !, ? ë’¤ ê³µë°± ê¸°ì¤€) â€” ë„¤ëœë€ë“œì–´ í¬í•¨ ì¼ë°˜ì  ì¼€ì´ìŠ¤ ì»¤ë²„
    sentences = re.split(r"(?<=[.!?])\s+", text)
    preview = " ".join(sentences[:max_sentences]).strip()
    # ê¸€ì ìˆ˜ ì œí•œ
    if len(preview) > max_chars:
        cut = preview[:max_chars]
        # ë§ˆì§€ë§‰ ë‹¨ì–´ ê²½ê³„ì—ì„œ ìë¥´ê¸°
        if " " in cut:
            cut = cut.rsplit(" ", 1)[0]
        preview = cut.rstrip(" .,;:") + "â€¦"
    return preview

# --------------------- Trefwoordenextractie ---------------------
def extract_keywords(text: str, top_n: int = 10):
    words = re.findall(r"\b[a-zA-Z]{8,}\b", text)
    capitalized_words = [w.capitalize() for w in words]
    filtered_words = [w for w in capitalized_words if w.lower() not in dutch_stopwords]
    freq = Counter(filtered_words)

    unique_keywords = []
    for word, _ in freq.most_common():
        if word not in unique_keywords:
            unique_keywords.append(word)
        if len(unique_keywords) >= top_n:
            break

    return [(kw, freq[kw]) for kw in unique_keywords], filtered_words

# --------------------- RSS Fetch ---------------------
def fetch_rss_items(feed_url: str, count: int = 5, progress_bar=None):
    parsed = feedparser.parse(feed_url)
    entries = parsed.entries or []

    total = min(count, len(entries)) if entries else 0
    out = []
    h = html2text.HTML2Text()
    h.ignore_links = False
    h.body_width = 0

    for i, e in enumerate(entries[:total], start=1):
        title = getattr(e, "title", "(geen titel)")
        link = getattr(e, "link", "")
        summary_html = getattr(e, "summary", getattr(e, "description", ""))
        summary_md = h.handle(summary_html).strip()

        keywords, _ = extract_keywords(f"{title}\n{summary_md}")

        out.append({
            "title": title,
            "url": link,
            "summary": summary_md,  # ì›ë³¸ ìš”ì•½(ì „ì²´) â€” í™”ë©´í‘œì‹œëŠ” make_safe_previewë¡œ ì œí•œ
            "keywords": [kw for kw, _ in keywords],
        })

        if progress_bar:
            progress_bar.progress(int(i / max(total, 1) * 100))

    if progress_bar:
        progress_bar.empty()

    return out

# --------------------- CSV ---------------------
def generate_csv_bytes(result):
    if not result:
        return None
    output = io.StringIO()
    writer = csv.DictWriter(output, fieldnames=["index", "title", "url", "keywords"])
    writer.writeheader()
    for idx, item in enumerate(result, 1):
        writer.writerow({
            "index": idx,
            "title": item["title"],
            "url": item["url"],
            "keywords": ", ".join(item["keywords"]),
        })
    return output.getvalue().encode("utf-8-sig")

# --------------------- UI ---------------------
presets = {
    "NOS Nieuws Algemeen": "https://feeds.nos.nl/nosnieuwsalgemeen",
    "NOS Binnenland": "https://feeds.nos.nl/nosnieuwsbinnenland",
    "NOS Buitenland": "https://feeds.nos.nl/nosnieuwsbuitenland",
    "NOS Politiek": "https://feeds.nos.nl/nosnieuwspolitiek",
    "NOS Economie": "https://feeds.nos.nl/nosnieuwseconomie",
    "NOS Tech": "https://feeds.nos.nl/nosnieuwstech",
    "NOS Opmerkelijk": "https://feeds.nos.nl/nosnieuwsopmerkelijk",
    "NOS Sport Algemeen": "https://feeds.nos.nl/nossportalgemeen",
}

left, right = st.columns([2, 3])
with left:
    preset_name = st.selectbox("RSS í”„ë¦¬ì…‹ ì„ íƒ", list(presets.keys()) + ["Custom"])

with right:
    default_url = presets.get(preset_name, "https://feeds.nos.nl/nosnieuwsalgemeen")
    feed_url = st.text_input("ë˜ëŠ” RSS URL ì§ì ‘ ì…ë ¥", value=default_url, help="ë§¤ì²´ì˜ ê³µì‹ RSS URLì„ ì…ë ¥í•˜ì„¸ìš”.")

article_count = st.slider("í•­ëª© ìˆ˜", 1, 20, 5)

# --------------------- Start Crawling ---------------------
if st.button("RSS ê°€ì ¸ì˜¤ê¸°"):
    progress = st.progress(0)
    result = fetch_rss_items(feed_url, article_count, progress)
    if result:
        st.session_state["rss_result"] = result
        st.success(f"âœ… {len(result)}ê°œì˜ ë‰´ìŠ¤ í•­ëª©ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")

# --------------------- Show Results ---------------------
if "rss_result" in st.session_state:
    result = st.session_state["rss_result"]

    for i, item in enumerate(result, 1):
        st.markdown(f"### {i}. {item['title']}")
        st.markdown(f"ğŸ”— [ì›ë¬¸ ë§í¬]({item['url']})")
        st.markdown(f"**Trefwoorden:** {', '.join(item['keywords'])}")
        with st.expander("ìš”ì•½ ë³´ê¸° (ìµœëŒ€ 3ë¬¸ì¥Â·500ì)"):
            preview = make_safe_preview(item["summary"])  # í•­ìƒ ì§§ê²Œ ì œí•œëœ ìš”ì•½ë§Œ ë…¸ì¶œ
            st.markdown(preview or "(ìš”ì•½ ì—†ìŒ)")
            if item["url"]:
                st.markdown(f"_Bron: [NOS.nl]({item['url']})_")

    if st.button("ğŸ“¥ CSV ì €ì¥í•˜ê¸°"):
        csv_bytes = generate_csv_bytes(result)
        if csv_bytes:
            st.session_state["csv_data"] = csv_bytes
            st.success("âœ… CSV íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    if "csv_data" in st.session_state:
        st.download_button(
            label="ğŸ“„ CSV ë‹¤ìš´ë¡œë“œ",
            data=st.session_state["csv_data"],
            file_name=f"nos_rss_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
            mime="text/csv",
        )
